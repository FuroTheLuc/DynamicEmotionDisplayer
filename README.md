# DynamicEmotionDisplayer

[![GitHub stars](https://img.shields.io/github/stars/FuroTheLuc/DynamicEmotionDisplayer.svg?style=flat&logo=github&color=yellow)](https://github.com/your_username/your_repo/stargazers)
[![GitHub forks](https://img.shields.io/github/forks/FuroTheLuc/DynamicEmotionDisplayer.svg?style=flat&logo=github&color=green)](https://github.com/your_username/your_repo/network)
[![GitHub issues](https://img.shields.io/github/issues/FuroTheLuc/DynamicEmotionDisplayer.svg?style=flat&logo=github)](https://github.com/your_username/your_repo/issues)

## Description

The DynamicEmotionDisplayer is a software that combines networking and VR-Controller inputs to display certain images on a different device. The main purpose i developed it for was use with cosplaying suits, e.g. "Fursuits", to be used as dynamic eyes that can display different emotions or images based on the input of the controllers in your hand. It is designed to be "Prietty easy" to use, and should be fairly easily used.

### Requirements:
 - 2 Identical Tablets and/or Mobile devices running Android
 - An oculus Quest/Ques 2
 - A third mobile device or any device able to create a local wifi hotspot for all subsidiary devices to connect to. (**the hotspot DOES NOT require internet access**!!)

## Table of Contents

- [Installation](#installation)
- [Usage](#usage)
- [License](#license)

## Installation

- Download the Unity Project and run it in Unity 2022
- Open the Project
Inside /assets/scenes will be the 2 main scenes. "SampleScene" Will be the Scene running on your headset. "SampleSceneCLIMOB" will be running on your Mobile Clients.
- Follow the tutorial on the setup

## Usage

Provide examples and usage of your project.
## License

This project is licensed under the [MIT License](LICENSE).
